{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "24168426-f506-43a9-aaf4-a4ba0d29bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go into requirements.txt \n",
    "# !pip -q install pandas\n",
    "# !pip -q install nltk\n",
    "# !pip -q install torchtext\n",
    "# !pip install -q torch \n",
    "# !pip install -q pytorch_lightning\n",
    "# !pip install -q torchvision\n",
    "# !pip -q install torch\n",
    "#!pip -q install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "756abe3e-d50f-4633-8a0c-dfa25da32bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch \n",
    "# with zipfile.ZipFile('./data/ag-news-classification-dataset.zip') as zf:\n",
    "#     zf.extractall('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1ec22f1e-ea0d-4cf9-9e7b-8115d2791173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets.py\n",
    "trainpath = '../data/train.csv'\n",
    "testpath = '../data/test.csv'\n",
    "train = pd.read_csv(trainpath)\n",
    "test = pd.read_csv(testpath)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e9d1893f-04f2-4de1-81de-ba33af9c88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Title and Description\n",
    "# clean and tokenize \n",
    "from torchtext.data import get_tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "try:\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "except LookupError as e:\n",
    "    print(f\"{e}, {e.__class__}\")\n",
    "    nltk.download('stopwords')\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "feab7aaa-085e-4a50-beeb-389466cb1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/P76114511/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8b22043c-42cf-461a-8f82-db84a92945a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(title, descrip):\n",
    "    text = title + '.' + descrip\n",
    "    text = re.sub(r'[~`\\-!@#$%^&*():;\"{}_/?><\\|.,`0-9\\\\]',' ',text)\n",
    "    # text = nltk.word_tokenize(text)     # as suggested by senpai \n",
    "    text = text.split()\n",
    "    text = [tok.lower() for tok in text if tok not in stopwords]\n",
    "    return text\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def build_vocab(datasets):\n",
    "      for dataset in datasets:\n",
    "        for rid, data in dataset.iterrows():\n",
    "            text = data['preproc_text']\n",
    "            yield text\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train['preproc_text'] = train.apply(lambda x:preproc(x['Title'], x['Description']), axis=1)\n",
    "test['preproc_text'] = test.apply(lambda x:preproc(x['Title'], x['Description']), axis=1)\n",
    "train['label'] = train['Class Index'].apply(lambda x:x-1)\n",
    "test['label'] = test['Class Index'].apply(lambda x:x-1)\n",
    "# train['Class Index'].unique() # array([3, 4, 2, 1])\n",
    "\n",
    "# class IterableTexts:\n",
    "#   def __iter__(self):\n",
    "#     for dataset in [trainset, testset]:\n",
    "#         for data in dataset:\n",
    "#             text = data['text']\n",
    "#             yield list(x.lower() for x in tokenizer(text) if x.lower() not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cb7d0cec-09a3-408f-8d40-a7e1320cfd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    30000\n",
       "3    30000\n",
       "1    30000\n",
       "0    30000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "21dc94e5-c9ce-4241-8203-c6ed77387756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4aea6163-05f8-47e0-bba5-10f3f0f0d97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28372\n"
     ]
    }
   ],
   "source": [
    "vocabs = build_vocab_from_iterator(build_vocab([train, test]), \n",
    "                                   specials=[\"[PAD]\", \"[UNK]\"], \n",
    "                                   min_freq = Config['MIN_FREQ'],\n",
    "                                   max_tokens =None)\n",
    "vocabs.set_default_index(vocabs[\"[UNK]\"]) # let padding be index 0 \n",
    "print(len(vocabs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ba8df-7583-4c2a-83f6-4af312445098",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ce084b89-7699-4af0-8fc3-dff239d47813",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = {\n",
    "    'IS_BIDIRECTIONAL':False,\n",
    "    'SEED':42,\n",
    "    'NUM_WORKER':12,\n",
    "    'BATCHSIZE': 200,\n",
    "    'LR':5e-4,\n",
    "    'NUM_LAYERS':2,\n",
    "    'MAXLEN':50,\n",
    "    'MIN_FREQ':5,\n",
    "    'DATASET':'AGNews', \n",
    "    'EPOCHS':20,\n",
    "    'WEIGHT_DECAY':1e-5,  #default:0\n",
    "    'DROPOUT':0.3, \n",
    "    'CLIP_GRAD':0.5,\n",
    "    'NUMCHOICE':4,\n",
    "    'LSTM_HDIM':256, \n",
    "    'EMBDIM':32,\n",
    "    'HIDDIM':32\n",
    "}\n",
    "LabelMapping = {0:\"World\",\n",
    "                1:\"Sports\",\n",
    "                2:\"Business\",\n",
    "                3:\"Sci/Tech\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "27445b54-2c29-4ea0-b1a6-4acf319b88e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 30000, 3: 30000, 1: 30000, 0: 30000})"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    maxlen = Config['MAXLEN']            # nltk.word_tokenize, spacy (better tokenize)\n",
    "    x = x[:maxlen]                      # truncation\n",
    "    tokenized_x = np.zeros(maxlen)      # padding: np.ones since [PAD]: 0\n",
    "    tokenized_x[:len(x)] = np.array([vocabs[v] for v in x])\n",
    "    return tokenized_x\n",
    "trainX = train['preproc_text'].apply(lambda x:tokenize(x))\n",
    "trainy = train['label']\n",
    "from collections import Counter\n",
    "Counter(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b101ce03-a7cb-46cb-886c-d1234478aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = torch.tensor(np.vstack(trainX), dtype=torch.long)\n",
    "trainy = torch.tensor(trainy, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "02f79de8-f3c7-4e7b-a4d7-e12233ca7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = test['preproc_text'].apply(lambda x:tokenize(x))\n",
    "testy = test['label']\n",
    "testX = torch.tensor(np.vstack(testX), dtype=torch.long)\n",
    "testy = torch.tensor(testy, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e3513f86-f2b5-4973-89ce-c6abc1fcc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120000, 50])\n",
      "torch.Size([120000])\n",
      "torch.Size([7600, 50])\n",
      "torch.Size([7600])\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainy.shape)\n",
    "print(testX.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "99fd90cb-04d7-4e98-99e1-b983be135857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap into dataloaders, collator and shuffling \n",
    "# Dataloader \n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "trainset = TensorDataset(trainX, trainy)\n",
    "testset = TensorDataset(testX, testy)\n",
    "trainloader = DataLoader(trainset, shuffle = True,\n",
    "                         num_workers = Config['NUM_WORKER'],\n",
    "                         batch_size=Config['BATCHSIZE'])\n",
    "testloader = DataLoader(testset, shuffle = False, \n",
    "                        num_workers = Config['NUM_WORKER'],\n",
    "                        batch_size=Config['BATCHSIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1046f763-d5f5-4bc0-84c8-f1ab41a6ce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size(including specials): 28372\n",
      "random index: 3278\n",
      "tokenized example:\n",
      " tensor([ 8722,  1814,   154,   712,  4938,    11,    48,   271,   154,  1523,\n",
      "         2725,   321,  1018,   418,  8722,  3547,  5455,  5296,  4605,  2116,\n",
      "            2,  1018,   852,   336, 15302,     1,    28,    38,   334,     4,\n",
      "           13,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "label: Sci/Tech\n",
      "detokenized example:\n",
      "['compuware', 'blasts', 'ibm', 'legal', 'tactics', 'two', 'years', 'ago', 'ibm', 'ordered', 'produce', 'source', 'code', 'products', 'compuware', 'identified', 'containing', 'pirated', 'intellectual', 'property', 'the', 'code', 'missing', 'but', 'lo', '[UNK]', 'last', 'week', 'called', 'said', 'quot', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, trainX.shape[0])\n",
    "detokenizer = vocabs.get_itos()\n",
    "print(f'Vocab Size(including specials): {len(vocabs.get_itos())}')\n",
    "print(f'random index: {r}')\n",
    "\n",
    "# “World”: 0,“Sports”: 1,“Business”: 2,“Sci/Tech”: 3\n",
    "\n",
    "x = trainX[r,:]\n",
    "print(f'tokenized example:\\n {x}')\n",
    "print(f'label: {LabelMapping[trainy[r].item()]}')\n",
    "print(f'detokenized example:')\n",
    "print([detokenizer[tok] for tok in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5a2eeac4-20aa-4352-81c5-883ce14262b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Config['VOCAB_SIZE'] = len(vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48e1ec-572f-4676-9bdd-e903ba7f14a6",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7208cfff-cd95-4b83-93a8-d8a1f349bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics # Accuracy\n",
    "pl.utilities.seed.seed_everything(Config['SEED'])\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim= Config['VOCAB_SIZE'], \n",
    "#                     output_dim= Config['EMBDIM'],  \n",
    "#                     input_length=Config['MAXLEN'], name = 'embedding'))\n",
    "# model.add(LSTM(Config['LSTM_HDIM'],name = 'lstm')) \n",
    "# model.add(Dense(Config['HIDDIM'], name = 'fc')) # 這裡不應該有softmax\n",
    "# model.add(Dropout(0.3, name = 'dropout'))\n",
    "# model.add(Dense(Config['NUMCHOICE'], activation=\"softmax\", name = 'classifier'))\n",
    "# model.summary()\n",
    "\n",
    "class LSTMNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # variables\n",
    "        self.num_directions = 2 if Config['IS_BIDIRECTIONAL'] else 1\n",
    "        self.LossFn = nn.CrossEntropyLoss(\n",
    "            ignore_index=vocabs['PAD']\n",
    "        )\n",
    "        self.lstm_hdim = Config['LSTM_HDIM']\n",
    "        \n",
    "        # layers \n",
    "        self.Embedding = nn.Embedding(Config['VOCAB_SIZE'], Config['EMBDIM'])\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "        self.Embedding.weight.data.uniform_(-1, 1)\n",
    "\n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size = Config['EMBDIM'],\n",
    "            hidden_size = Config['LSTM_HDIM'],\n",
    "            num_layers = Config['NUM_LAYERS'],\n",
    "            bidirectional = Config['IS_BIDIRECTIONAL'],\n",
    "            batch_first = True,\n",
    "        )\n",
    "        self.FC = nn.Linear(Config['LSTM_HDIM']*self.num_directions, \n",
    "                            Config['HIDDIM'])\n",
    "        self.Dropout = nn.Dropout(Config['DROPOUT'])  \n",
    "        self.Out  = nn.Linear(Config['HIDDIM'], Config['NUMCHOICE'])\n",
    "        \n",
    "        # metrics\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # https://zhenglungwu.medium.com/pytorch%E5%AF%A6%E4%BD%9Clstm%E5%9F%B7%E8%A1%8C%E8%A8%8A%E8%99%9F%E9%A0%90%E6%B8%AC-d1d3f17549e7\n",
    "        x = self.Embedding(x)\n",
    "        x, (h, c) = self.LSTM(x)\n",
    "        x = self.FC(x)\n",
    "        x = self.Dropout(x)\n",
    "        x = self.Out(x)\n",
    "        x = x[:, -1]\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        X, labels = batch \n",
    "        preds = self(X)\n",
    "        loss = self.LossFn(preds, labels)\n",
    "        accuracy = self.accuracy(torch.argmax(preds, axis=1), \n",
    "                                 labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        X, labels = batch \n",
    "        preds = self(X)\n",
    "        loss = self.LossFn(preds, labels)\n",
    "        accuracy = self.accuracy(torch.argmax(preds, axis=1), labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), \n",
    "                                     lr=Config['LR'])\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d1f2222-1764-4784-8282-81bfcd56071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "target = torch.tensor([0, 3])\n",
    "preds = torch.tensor([[0, 0.5, 0.8, 0.2],\n",
    "                      [0.2,0.1,0.1,0.3]])\n",
    "preds = torch.argmax(preds, axis=1)\n",
    "print(preds)\n",
    "accuracy = Accuracy()\n",
    "accuracy(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "82470efc-43f3-4f14-9ecb-5a508e9723b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (LossFn): CrossEntropyLoss()\n",
      "  (Embedding): Embedding(28372, 32)\n",
      "  (LSTM): LSTM(32, 256, num_layers=2, batch_first=True)\n",
      "  (FC): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (Dropout): Dropout(p=0.3, inplace=False)\n",
      "  (Out): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (accuracy): Accuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# set up Lightning model architecture \n",
    "model = LSTMNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "910ebbda-6a20-45ca-afb9-5014d268d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | LossFn    | CrossEntropyLoss | 0     \n",
      "1 | Embedding | Embedding        | 907 K \n",
      "2 | LSTM      | LSTM             | 823 K \n",
      "3 | FC        | Linear           | 8.2 K \n",
      "4 | Dropout   | Dropout          | 0     \n",
      "5 | Out       | Linear           | 132   \n",
      "6 | accuracy  | Accuracy         | 0     \n",
      "-----------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.958     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011483907699584961,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011973381042480469,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c24772b2304259beda0524f8526fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011938333511352539,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012310981750488281,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011831521987915039,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011695384979248047,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01214456558227539,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011814117431640625,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011675119400024414,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011978387832641602,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011791467666625977,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012054681777954102,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011820793151855469,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011651992797851562,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01227426528930664,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012305259704589844,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/P76114511/main/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# Trainer.fit \n",
    "\n",
    "pl.utilities.seed.seed_everything(Config['SEED'])\n",
    "trainer = pl.Trainer(max_epochs = Config['EPOCHS'], \n",
    "                     gradient_clip_val=Config['CLIP_GRAD'],\n",
    "                     accelerator=\"gpu\", \n",
    "                     devices=1)\n",
    "trainer.fit(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7fc4953a-1b74-4883-93ec-a9bd04903caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011688232421875,
       "initial": 0,
       "n": 0,
       "ncols": 166,
       "nrows": 48,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6630f83f2ac44dc9a6034c5d66743a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.6702631711959839\n",
      "        val_loss            0.4220391511917114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.4220391511917114, 'val_acc': 0.6702631711959839}]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, dataloaders=testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330716e-fc6d-4592-b157-24296ddb8e62",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "205cb21e-87e1-457c-8a96-e97b155342ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "golds = []\n",
    "model.eval()\n",
    "\n",
    "for X, y in testloader:\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(X)\n",
    "        y_hat = torch.argmax(y_hat, axis = 1)\n",
    "    golds.extend(y.numpy())\n",
    "    preds.extend(y_hat.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a993a2-0ca1-43e4-bf91-de90f1b61afb",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0f06a8b1-16f9-4501-a911-aeb1a67684ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1715,    0,   93,   92],\n",
       "       [1117,    0,  404,  379],\n",
       "       [  68,    0, 1677,  155],\n",
       "       [  46,    0,  152, 1702]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(golds, preds)\n",
    "#???? 完全沒有預測 Sports \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "73dbb3ca-9d8b-4833-8ddb-44ed811f4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6702631578947369"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as SKACC\n",
    "SKACC(golds, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
